{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTree, Ensemble, Random Forest\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 이진트리 분류기 만들기\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    이름  직업    키 성별\n",
      "0   하하  가수  171  M\n",
      "1  김범수  가수  182  M\n",
      "2   다현  가수  158  F\n",
      "3  아이유  가수  160  F\n",
      "4  최민식  배우  177  M\n",
      "5  김혜수  배우  170  F \n",
      "\n",
      "Node_num : 1 | Node Depth : 1 | Sex_Node\n",
      "남자 Index :  [0, 1, 4]\n",
      "여자 Index :  [2, 3, 5]\n",
      "Node_num : 2 | Node Depth : 2 | Job_Node\n",
      "Node_num : 3 | Node Depth : 2 | Name : 최민식\n",
      "가수 Index :  [0, 1]\n",
      "Node_num : 4 | Node Depth : 3 | Height_Node\n",
      "Node_num : 5 | Node Depth : 4 | Name : 하하\n",
      "Node_num : 6 | Node Depth : 4 | Name : 김범수\n",
      "Node_num : 7 | Node Depth : 2 | Job_Node\n",
      "Node_num : 8 | Node Depth : 2 | Name : 김혜수\n",
      "가수 Index :  [2, 3]\n",
      "Node_num : 9 | Node Depth : 3 | Height_Node\n",
      "Node_num : 10 | Node Depth : 4 | Name : 다현\n",
      "Node_num : 11 | Node Depth : 4 | Name : 아이유\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 직업, 키, 성별로 이름을 구분하는 간단한 이진트리 분류기를 만들어보겠습니다.\n",
    "name = ['하하', '김범수', '다현', '아이유', '최민식', '김혜수']\n",
    "job  = ['가수', '가수'  , '가수', '가수'  , '배우'  , '배우']\n",
    "height = [171, 182, 158, 160, 177, 170]\n",
    "sex = ['M', 'M', 'F', 'F', 'M', 'F']\n",
    "\n",
    "# Node 번호를 지정해주기 위한 변수\n",
    "num = 0\n",
    "\n",
    "# 데이터 프레임 만들기\n",
    "data = pd.DataFrame({'이름': name, '직업': job, '키': height,'성별': sex})\n",
    "print(data,'\\n')\n",
    "\n",
    "# 키 분류 Node\n",
    "def Height_Node(df, idx, depth):\n",
    "    # 전역 변수를 함수 내에서 사용하기 위해 Global 선언\n",
    "    global num\n",
    "    num +=1\n",
    "    # Node num, Depth, Node Name 출력\n",
    "    print('Node_num : {} | Node Depth : {} | Height_Node'.format(num, depth))\n",
    "    \n",
    "    for i in idx:\n",
    "        num +=1\n",
    "        # 성별에 따라 키의 기준이 다르기 때문에 성별을 우선 분류\n",
    "        if df['성별'][i] == 'M':\n",
    "            # 남자의 경우 키에 따라 분류\n",
    "            # 키가 180보다 작은 경우\n",
    "            if df['키'][i] < 180:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1, df['이름'][i]))\n",
    "            # 키가 180보다 큰 경우\n",
    "            else:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1, df['이름'][i]))\n",
    "        else:\n",
    "            # 여자의 경우 키에 따라 분류\n",
    "            # 키가 160보다 작은 경우\n",
    "            if df['키'][i] < 160:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1, df['이름'][i]))\n",
    "            # 키가 160보다 큰 경우\n",
    "            else:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1, df['이름'][i]))\n",
    "\n",
    "# 직업 분류 Node\n",
    "def Job_Node(df,idx, depth):\n",
    "    # 전역 변수를 함수 내에서 사용하기 위해 Global 선언\n",
    "    global num\n",
    "    num +=1\n",
    "    \n",
    "    # Node num, Depth, Node Name 출력\n",
    "    print('Node_num : {} | Node Depth : {} | Job_Node'.format(num, depth))\n",
    "    \n",
    "    # Index 저장을 위한 리스트 \n",
    "    singer = []\n",
    "    \n",
    "    for i in idx:\n",
    "        # 가수인 경우 Index 저장\n",
    "        if df['직업'][i] == '가수':\n",
    "            singer.append(i)\n",
    "            \n",
    "        # 배우인 경우 Node 번호와 해당 배우의 이름 출력    \n",
    "        else:\n",
    "            num += 1\n",
    "            print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth, df['이름'][i]))\n",
    "    \n",
    "    # 가수인 경우 분류가 끝나지 않았으므로 Index 출력\n",
    "    print('가수 Index : ',singer)\n",
    "    \n",
    "    # 마지막 분류 기준인 키를 통해 가수를 분류\n",
    "    # 다음 Node를 호출할 때 depth를 하나 증가시켜줍니다.\n",
    "    Height_Node(df, singer, depth+1)\n",
    "\n",
    "# 성별 분류 Node\n",
    "def Sex_Node(df, depth):\n",
    "    # 전역 변수를 함수 내에서 사용하기 위해 Global 선언\n",
    "    global num\n",
    "    # Node num, Depth, Node Name 출력\n",
    "    num +=1\n",
    "    print('Node_num : {} | Node Depth : {} | Sex_Node'.format(num, depth))\n",
    "    \n",
    "    male = []\n",
    "    female = []\n",
    "    # 처음 성별 데이터 전체로 분류\n",
    "    for idx, sex in enumerate(df['성별']):\n",
    "        # 남자인 경우 Index 저장\n",
    "        if sex == 'M':\n",
    "            male.append(idx)\n",
    "        # 여자인 경우 Index 저장\n",
    "        elif sex == 'F':\n",
    "            female.append(idx)\n",
    "    \n",
    "    # Index 확인\n",
    "    print('남자 Index : ',male)\n",
    "    print('여자 Index : ',female)\n",
    "    \n",
    "    # 성별 분류 후 직업을 분류하는 Node를 호출합니다.\n",
    "    # 다음 Node를 호출할 때 depth를 하나 증가시켜줍니다.\n",
    "    Job_Node(df, male, depth+1)\n",
    "    Job_Node(df, female, depth+1)\n",
    "\n",
    "# 첫 번째 분류 기준으로 성별을 설정합니다.\n",
    "Sex_Node(data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의사 결정 트리(DecisionTreeClassifier)\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 정확도 : 0.9000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def main():\n",
    "    # Iris 데이터 세트 불러오기\n",
    "    iris = load_iris()\n",
    "    # Iris 데이터 세트 Train과 Test 분할하기\n",
    "    # Train : Test = 8 : 2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.2)\n",
    "    \n",
    "    # 의사 결정 트리 불러오기\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    \n",
    "    # 의사 결정 트리 학습\n",
    "    dtree.fit(X_train, y_train)\n",
    "    \n",
    "    # 검증 데이터로 결과 예측\n",
    "    pred = dtree.predict(X_test)\n",
    "    print('검증 데이터 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 파라미터 찾기 : GridSearceCV\n",
    "    ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 :  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.9464\n",
      "Test Dataset accuracy : 0.9737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def main():\n",
    "    # Iris 데이터 세트 불러오기\n",
    "    iris = load_iris()\n",
    "    # Iris 데이터 세트 Train과 Test 분할하기\n",
    "    X_train, X_test, y_train,y_test = train_test_split(iris.data, iris.target)\n",
    "    \n",
    "    # 의사 결정 트리 불러오기\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    \n",
    "    # 의사 결정 트리의 인자 값 설정\n",
    "    # 학습을 진행할 때 트리의 깊이와 각 트리당 노드의 개수를 정해줍니다. \n",
    "    param_grid = {'max_depth' : [1,2,3], 'min_samples_split' : [2,3]}\n",
    "    \n",
    "    # 이러면 총 6가지 경우에 대해 학습을 진행하며 최종적으로는 GridSearchCV가 가장 성능이 좋은 파라미터를 선택합니다.\n",
    "    grid_dtree = GridSearchCV(dtree, param_grid = param_grid, cv = 5, refit= True, return_train_score=True, iid = True)\n",
    "    \n",
    "    # 의사 결정 트리 학습\n",
    "    grid_dtree.fit(X_train, y_train)\n",
    "    \n",
    "    # 출력을 위한 데이터 프레임 만들기\n",
    "    scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "    scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]\n",
    "    \n",
    "    # GridSearchCV()가 가지고 있는 속성들을 불러 결과를 출력해보세요.\n",
    "    print('GridSearchCV 최적 파라미터 : ', grid_dtree.best_params_)\n",
    "    print('GridSearchCV 최고 정확도 : {0:.4f}'.format(grid_dtree.best_score_))\n",
    "    \n",
    "    # 최적의 파라미터로 학습된 트리 Estimator 가져오세요.\n",
    "    estimator = grid_dtree.best_estimator_\n",
    "    \n",
    "    # 검증 데이터로 결과 예측\n",
    "    pred = estimator.predict(X_test)\n",
    "    print('Test Dataset accuracy : {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블(Ensemble) 학습 (1)\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier 정확도 : 0.9441\n",
      "KNeighborsClassifier 정확도 : 0.9301\n",
      "LogisticRegression 정확도 : 0.9510\n",
      "VotingClassifier 정확도 : 0.9441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 유방암 데이터 불러오기\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 데이터 프레임을 만들기\n",
    "data_df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "\n",
    "# Voting과 비교할 각각 다른 분류기 불러오기\n",
    "# KNeighborsClassifier, LogisticRegression\n",
    "lr_clf = KNeighborsClassifier()\n",
    "knn_clf = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "# Voting에 사용할 분류기\n",
    "# 분류기로 LogisticRegressor와 KNeighborClassifier를 사용합니다.\n",
    "# Voting 방식은 Soft Voting을 사용합니다.\n",
    "vo_clf = VotingClassifier(estimators=[('lr', lr_clf), ('knn', knn_clf)], voting='soft')\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 나누기\n",
    "X_train, X_test, y_train,y_test = train_test_split(data_df, cancer.target, test_size = 0.25) \n",
    "\n",
    "# Voting Classifier 학습\n",
    "vo_clf.fit(X_train, y_train)\n",
    "\n",
    "# Voting 결과 예측\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting Classifier 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "\n",
    "# 다른 분류기를 각각 학습했을 때 결과 예측\n",
    "# classifiers에 lr_clf, knn_clf를 넣어주세요.\n",
    "classifiers = [lr_clf, knn_clf, vo_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print(\"{0} 정확도 : {1:.4f}\".format(class_name, accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블(Ensemble) 학습 (2)\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라미터      :  {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 1}\n",
      "최고 예측 정확도   : 0.9231\n",
      "검증 데이터 정확도 : 0.9211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 유방암 데이터 세트 불러오기\n",
    "bc = load_breast_cancer()\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 분할하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc.data, bc.target, test_size = 0.2, random_state = 121)\n",
    "\n",
    "# RandomForestClassifier 객체 불러오기\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# GridSearchCV에 넣을 파라미터\n",
    "param ={\n",
    "    'n_estimators'      : [1],\n",
    "    'max_depth'         : [1,2],\n",
    "    'min_samples_leaf'  : [1,2],\n",
    "    'min_samples_split' : [2,3]\n",
    "}\n",
    "\n",
    "# GridSearchCV 불러오기\n",
    "grid_rfc = GridSearchCV(rfc, param_grid = param, cv = 5, iid = True)\n",
    "\n",
    "# RandomForestClassifier 학습\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고 예측 정확도 계산\n",
    "print('최적 파라미터      : ', grid_rfc.best_params_)\n",
    "print('최고 예측 정확도   : {0:.4f}'.format(grid_rfc.best_score_))\n",
    "\n",
    "# 최적의 파라미터로 학습된 트리 Estimator 가져오기\n",
    "estimator = grid_rfc.best_estimator_\n",
    "\n",
    "# 검증 데이터로 결과 예측\n",
    "pred = estimator.predict(X_test)\n",
    "print('검증 데이터 정확도 : {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 1, 교차 검증 정확도 : 0.8611\n",
      "Iter : 2, 교차 검증 정확도 : 0.8507\n",
      "Iter : 3, 교차 검증 정확도 : 0.8432\n",
      "Iter : 4, 교차 검증 정확도 : 0.8641\n",
      "Iter : 5, 교차 검증 정확도 : 0.8502\n",
      "교차 검증 평균 정확도 : 0.8539\n",
      "GridSearchCV 최적 파라미터 :  {'max_depth': 17, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.8461\n",
      "검증 데이터 정확도 : 0.8250\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# digits 데이터를 불러오고 feature와 label에 data와 target을 저장해주세요.\n",
    "digits = load_digits()\n",
    "feature = digits.data\n",
    "label = digits.target\n",
    "\n",
    "# DecisionTreeClassifier를 불러와주세요.\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# GridSearchCV에 사용할 Param 값을 정해주세요.\n",
    "param_grid = {'max_depth' : [14,15,16,17,18,19], 'min_samples_split' : [2,3,4,5,6]}\n",
    "\n",
    "# 파라미터를 설정해주세요.\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits = n_splits)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "# 데이터를 분리해주세요.\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size = 0.2)\n",
    "\n",
    "# X_train 데이터를 K-fold를 사용해서 총 5개의 fold로 나눠주세요.\n",
    "for train_idx, vali_idx in kfold.split(X_train):\n",
    "    X_fold_train, X_fold_vali = X_train[train_idx], X_train[vali_idx]\n",
    "    y_fold_train, y_fold_vali = y_train[train_idx], y_train[vali_idx]\n",
    "    \n",
    "    # GridSearchCV를 이용해 결정 트리를 학습시켜주세요.\n",
    "    grid_dtree = GridSearchCV(dt_clf, param_grid=param_grid, refit= True, cv = 5, iid = True)\n",
    "    grid_dtree.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Iter 별 교차 검증 정확도를 계산해보세요.\n",
    "    fold_pred = grid_dtree.predict(X_fold_vali)\n",
    "    \n",
    "    n_iter += 1\n",
    "    print('Iter : {0}, 교차 검증 정확도 : {1:.4f}'.format(n_iter ,accuracy_score(y_fold_vali, fold_pred)))\n",
    "    \n",
    "    # 교차 검증 평균 정확도를 위해 Iter별 교차 검증 정확도를 cv_accuracy에 넣어주세요.\n",
    "    cv_accuracy.append(accuracy_score(y_fold_vali, fold_pred))\n",
    "\n",
    "# 교차 검증 평균 정확도를 계산해주세요.\n",
    "cv_accuracy = sum(cv_accuracy) / len(cv_accuracy)\n",
    "print(\"교차 검증 평균 정확도 : {0:.4f}\".format(cv_accuracy))\n",
    "\n",
    "# GricSearchCV 최적 파라미터와 최고 정확도를 출력해보세요.\n",
    "print('GridSearchCV 최적 파라미터 : ', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도 : {0:.4f}'.format(grid_dtree.best_score_))\n",
    "    \n",
    "# 최적의 파라미터로 학습된 grid_dtree의 best_estimator를 불러와주세요.\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# 검증 데이터로 결과를 예측해보세요.\n",
    "pred = estimator.predict(X_test)\n",
    "\n",
    "# 검증 데이터 정확도를 출력해보세요.\n",
    "test_accuracy = accuracy_score(pred, y_test)\n",
    "print(\"검증 데이터 정확도 : {0:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
