{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation\n",
    "==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터세트 준비하기\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 정확도(accuracy) : 100.00%\n",
      "검증 정확도(accuracy) : 89.47%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Iris 데이터 세트 불러오기\n",
    "iris = load_iris()\n",
    "\n",
    "# Classification에 사용할 머신러닝 모델 불러오기\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 전체 데이터로 학습\n",
    "dt_clf.fit(iris.data, iris.target)\n",
    "\n",
    "# 전체 데이터로 검증\n",
    "pred = dt_clf.predict(iris.data)\n",
    "\n",
    "# 검증 정확도 출력\n",
    "# 학습한 데이터를 그대로 검증 데이터로 사용하면 정확도가 100%가 나오게 됩니다.\n",
    "# 그러나 올바른 학습과 검증의 과정이 아닙니다.\n",
    "print(\"검증 정확도(accuracy) : {0:.2f}%\".format(accuracy_score(iris.target, pred) * 100))\n",
    "\n",
    "\n",
    "# 전체 데이터를 학습 데이터와 검증 데이터로 나누어 머신러닝 모델을 평가합니다.\n",
    "# 데이터 세트를 나눔으로써 머신러닝 모델을 좀 더 일반화할 수 있습니다.\n",
    "X_train, X_test, Y_train, Y_test =  train_test_split(iris.data, iris.target, test_size = 0.25)\n",
    "\n",
    "# 학습 데이터로 모델 학습 진행\n",
    "dt_clf.fit(X_train, Y_train)  \n",
    "\n",
    "# 검증 데이터로 성능 평가\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "# 검증 정확도 출력\n",
    "print(\"검증 정확도(accuracy) : {0:.2f}%\".format( accuracy_score(Y_test, pred) * 100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_fold 교차 검증\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 1 Cross-Validation Accuracy : 1.0, Train Data 크기 : 120, Test Data 크기 : 30\n",
      "Iter : 2 Cross-Validation Accuracy : 0.9667, Train Data 크기 : 120, Test Data 크기 : 30\n",
      "Iter : 3 Cross-Validation Accuracy : 0.9, Train Data 크기 : 120, Test Data 크기 : 30\n",
      "Iter : 4 Cross-Validation Accuracy : 0.9333, Train Data 크기 : 120, Test Data 크기 : 30\n",
      "Iter : 5 Cross-Validation Accuracy : 0.7333, Train Data 크기 : 120, Test Data 크기 : 30\n",
      "평균 검증 정확도 :  0.9066599999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Iris 데이터 세트 불러오기\n",
    "iris = load_iris() \n",
    "# Classification에 사용할 모델 불러오기\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 몇 개의 Fold로 나눌지 결정합니다.\n",
    "n_iter = 0\n",
    "kfold = KFold(n_splits = 5)\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(iris.data):    # Data를 K만큼 나누기\n",
    "    X_train, X_test = iris.data[train_idx], iris.data[test_idx] # 나눈 데이터 저장\n",
    "    y_train, y_test = iris.target[train_idx], iris.target[test_idx]\n",
    "\n",
    "    dt_clf.fit(X_train,y_train)     # 모델 학습\n",
    "    pred = dt_clf.predict(X_test)   # 검증 데이터로 결과 예측\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)    # 각 Iter 별 정확도 측정\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print(\"Iter : {0} Cross-Validation Accuracy : {1}, Train Data 크기 : {2}, Test Data 크기 : {3}\"\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(\"평균 검증 정확도 : \", np.mean(cv_accuracy)) # 평균 검증 정확도 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified K-Fold 교차 검증\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "--------------------\n",
      "학습 데이터 분포 : \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "--------------------\n",
      "검증 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "--------------------\n",
      "Iter : 1, 정확도 : 98.04%, 학습 데이터 개수 : 99, 검증 데이터 개수 : 51\n",
      "\n",
      "Iteration : 2\n",
      "--------------------\n",
      "학습 데이터 분포 : \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "--------------------\n",
      "검증 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "--------------------\n",
      "Iter : 2, 정확도 : 92.16%, 학습 데이터 개수 : 99, 검증 데이터 개수 : 51\n",
      "\n",
      "Iteration : 3\n",
      "--------------------\n",
      "학습 데이터 분포 : \n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "--------------------\n",
      "검증 데이터 분포 : \n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n",
      "--------------------\n",
      "Iter : 3, 정확도 : 97.92%, 학습 데이터 개수 : 102, 검증 데이터 개수 : 48\n",
      "\n",
      "평균 검증 정확도 : 96.0400%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Iris 데이터 세트 불러오기\n",
    "iris = load_iris()\n",
    "\n",
    "# 데이터 분포를 확인하기 위해 DataFrame을 만들어줍니다.\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "# Classification에 사용할 모델 불러오기\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Iris 데이터는 3개의 Class로 이루어져 있습니다.\n",
    "# 그러므로 3개의 Fold로 데이터를 나눕니다.\n",
    "n_iter = 0\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "avg_acc = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(iris_df, iris_df['label']):    # iris 데이터에서 나누기\n",
    "    # Iter 수 증가\n",
    "    n_iter += 1\n",
    "    \n",
    "    # K 개수 만큼 Fold 나누기\n",
    "    train_label = iris_df['label'].iloc[train_idx]                  \n",
    "    test_label = iris_df['label'].iloc[test_idx]\n",
    "    X_train, X_test = iris.data[train_idx], iris.data[test_idx]\n",
    "    y_train, y_test = iris.target[train_idx], iris.target[test_idx]\n",
    "    \n",
    "    print(\"Iteration :\", n_iter)\n",
    "    print(\"--------------------\")\n",
    "    print(\"학습 데이터 분포 : \\n\", train_label.value_counts())\n",
    "    print(\"--------------------\")\n",
    "    print(\"검증 데이터 분포 : \\n\", test_label.value_counts())\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    # 학습 데이터로모델 학습\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    \n",
    "    # 검증 데이터로 성능 평가\n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print(\"Iter : {0}, 정확도 : {1}%, 학습 데이터 개수 : {2}, 검증 데이터 개수 : {3}\\n\"\n",
    "          .format(n_iter, accuracy*100, train_size, test_size))\n",
    "\n",
    "    avg_acc.append(accuracy)\n",
    "    \n",
    "print(\"평균 검증 정확도 : {0:.4f}%\".format(np.mean(avg_acc)* 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "# Load_digits()로 데이터를 불러오세요.\n",
    "digits = load_digits()\n",
    "\n",
    "# train_test_split()과 KFold()에 들어갈 파라미터를 설정해주세요.\n",
    "# Train : Test 비율 =  7 : 3\n",
    "# Fold의 개수 = 3\n",
    "test_size = 0.3\n",
    "n_splits = 3\n",
    "\n",
    "# Kfold를 선언해주세요.\n",
    "kfold = KFold(n_splits = n_splits)\n",
    "\n",
    "# train_test_split()으로 데이터를 나눠주세요.\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size = test_size)\n",
    "\n",
    "# K-Fold를 이용해 X_train을 3 Fold로 나눠보세요.\n",
    "for train_idx, vali_idx in kfold.split(X_train):\n",
    "    X_fold_train, X_fold_vali = digits.data[train_idx], digits.data[vali_idx]\n",
    "    y_fold_train, y_fold_vali = digits.target[train_idx], digits.target[vali_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave One Out(LOO)\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN : [1 2] TEST : [0]\n",
      "[[3 4]\n",
      " [5 6]] [[1 2]]\n",
      "TRAIN : [0 2] TEST : [1]\n",
      "[[1 2]\n",
      " [5 6]] [[3 4]]\n",
      "TRAIN : [0 1] TEST : [2]\n",
      "[[1 2]\n",
      " [3 4]] [[5 6]]\n"
     ]
    }
   ],
   "source": [
    "# 전체 n개의 데이터셋 중 1개만을 validation에 사용함\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    print('TRAIN :',train_idx, 'TEST :', test_idx)\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    print(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave P Out(LPO)\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN : [2] TEST : [0 1]\n",
      "[[5 6]] [[1 2]\n",
      " [3 4]]\n",
      "TRAIN : [1] TEST : [0 2]\n",
      "[[3 4]] [[1 2]\n",
      " [5 6]]\n",
      "TRAIN : [0] TEST : [1 2]\n",
      "[[1 2]] [[3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "lpo = LeavePOut(2)\n",
    "lpo.get_n_splits(X)\n",
    "\n",
    "for train_idx, test_idx in lpo.split(X):\n",
    "    print('TRAIN :', train_idx, 'TEST :', test_idx)\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    print(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle-Split\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1 3 0 4] TEST: [5 2]\n",
      "TRAIN: [4 0 2 5] TEST: [1 3]\n",
      "TRAIN: [1 2 4 0] TEST: [3 5]\n",
      "TRAIN: [3 4 1 0] TEST: [5 2]\n",
      "TRAIN: [3 5 1 0] TEST: [2 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
    "y = np.array([1, 2, 1, 2, 1, 2])\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
    "rs.get_n_splits(X)\n",
    "ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
