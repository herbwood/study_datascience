{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing and RNN\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natutal Languate Processing\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 전체 문서 읽어오기  \n",
    "### 2. 문서 나누기  \n",
    "### 3. BOW(Bag of Words) 구하기  \n",
    "### 4. TFIDF 구하기  \n",
    "### 5. 유사도 구하기(cosine, jaccard)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pictures/tfidf.jpg\" style=\"width: 600px\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "PATH_1 = \"datasets/robbie.txt\"\n",
    "PATH_2 = \"datasets/runaround.txt\"\n",
    "PATH_3 = \"datasets/reason.txt\"\n",
    "\n",
    "# 코사인 유사도(두 벡터 사이의 각도를 활용한 유사도)\n",
    "def cosine_similarity(x,y):\n",
    "    return np.dot(x,y) / (np.linalg.norm(x)*np.linalg.norm(y))\n",
    "\n",
    "# 자카드 유사도\n",
    "# (두 집합의 교집합) / (두 집합의 합집합)\n",
    "def jaccard(X, Y):\n",
    "    len_total = len(X+Y) # 중복 허용 전체 요소의 수\n",
    "    len_union = len(list(set(X+Y))) # 중복 허용하지 않는 전체 요소의 수\n",
    "    len_inter = len_total - len_union # 교집합 요소의 수\n",
    "    return len_inter / len_union\n",
    "\n",
    "# 단어와 빈도 수를 딕셔너리 형태로 저장\n",
    "def bag_of_words(tokenized_sentences):\n",
    "    word_dict={}\n",
    "    for tokenized_sentence in tokenized_sentences:\n",
    "        for token in tokenized_sentence:\n",
    "            try:\n",
    "                word_dict[token] += 1\n",
    "            except:\n",
    "                word_dict[token] = 1\n",
    "    return word_dict\n",
    "\n",
    "def read_txt(path):\n",
    "    file=open(path, 'r')\n",
    "    output=str(file.read())\n",
    "    return output\n",
    "\n",
    "# 형태소 단위로 문서를 분절함\n",
    "def get_splited_doc(path):\n",
    "    text = read_txt(path)\n",
    "    analyzer = Twitter()\n",
    "    output = analyzer.morphs(text)\n",
    "    return output\n",
    "\n",
    "def tf(doc, word):\n",
    "    return doc.count(word)\n",
    "    \n",
    "def idf(docs, word):\n",
    "    num=0\n",
    "    for doc in docs:\n",
    "        if doc.count(word)>0:\n",
    "            num+=1\n",
    "    return np.log(len(docs)/(1+num))\n",
    "\n",
    "\n",
    "def tf_idf(docs, bow):\n",
    "    len_vector= len(bow)\n",
    "    vectors=[]\n",
    "    keys = list(bow.keys())\n",
    "    for doc in docs:\n",
    "        vector = []\n",
    "        for i,key in enumerate(keys):\n",
    "            vector.append(tf(doc, key) * idf(docs, key))\n",
    "        vectors.append(vector)\n",
    "        \n",
    "    return vectors\n",
    "    \n",
    "def main():\n",
    "\n",
    "    robbie = get_splited_doc(PATH_1)\n",
    "    runaround = get_splited_doc(PATH_2)\n",
    "    reason = get_splited_doc(PATH_3)\n",
    "\n",
    "    total = [robbie, runaround, reason]\n",
    "\n",
    "    bow = bag_of_words(total)\n",
    "\n",
    "    vecs_tfidf = tf_idf(total, bow)\n",
    "    \n",
    "    robbie, runaround, reason = vecs_tfidf\n",
    "\n",
    "    csml_ro_run = cosine_similarity(robbie, runaround)\n",
    "    csml_ro_rea = cosine_similarity(robbie, reason)\n",
    "    \n",
    "    jsml_ro_run = jaccard(robbie, runaround)\n",
    "    jsml_ro_rea = jaccard(robbie, reason)\n",
    "    \n",
    "    print(\"Cosine similarity between robbie and runaround is\", csml_ro_run)\n",
    "    print(\"Cosine similarity between robbie and reason is\", csml_ro_rea)\n",
    "    print(\"Jaccard similarty beteween robbie and runaround is\", jsml_ro_run)\n",
    "    print(\"Jaccard similarty beteween robbie and reason is\", jsml_ro_rea)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pictures/rnn.jpg\" style=\"width: 600px\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.46214543]\n",
      " [0.7452483 ]\n",
      " [0.84695597]\n",
      " [0.87334142]\n",
      " [0.87945962]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rnn(inputs, output_size, bias = False):\n",
    "    input_size = len(inputs[0])\n",
    "    # 이전 결과값\n",
    "    state = np.zeros((output_size,))\n",
    "    \n",
    "    # 현재 입력값의 가중치\n",
    "    w = np.ones((output_size, input_size))\n",
    "    \n",
    "    # 이전 결과값의 가중치\n",
    "    u = np.ones((output_size, output_size))\n",
    "    \n",
    "    # 편향\n",
    "    b = np.random.random((output_size,))\n",
    "    \n",
    "    if not bias:\n",
    "        b = np.zeros((output_size,))\n",
    "        \n",
    "    outputs = []\n",
    "    \n",
    "    for _input in inputs:\n",
    "        _output = np.tanh(np.dot(w, _input) + np.dot(u, state) + b)\n",
    "        outputs.append(_output)\n",
    "        state=_output\n",
    "        \n",
    "    return np.stack(outputs, axis=0) \n",
    "\n",
    "\n",
    "def main():\n",
    "    _input = [[0], [0], [0], [0], [0]]\n",
    "    print(rnn(_input, output_size=1))\n",
    "    print(rnn(_input, output_size=1, bias = True))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
