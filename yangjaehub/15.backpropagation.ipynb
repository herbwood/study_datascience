{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN by Keras\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.5038 - acc: 0.8233\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.3785 - acc: 0.8637\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.3380 - acc: 0.8776\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3147 - acc: 0.8851\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.2959 - acc: 0.8894\n",
      "10000/10000 [==============================] - 1s 80us/step\n",
      "\n",
      "- TEST accuracy : 0.8753\n",
      "\n",
      "- train image shape : \n",
      " (60000, 28, 28)\n",
      "\n",
      "- train labels length : \n",
      " 60000\n",
      "\n",
      "- train labels : \n",
      " [9 0 0 ... 3 0 5]\n",
      "\n",
      "- test image shape : \n",
      " (10000, 28, 28)\n",
      "\n",
      "- test labels length : \n",
      " 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 1. load data\n",
    "    fashion_mnist = keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "    \n",
    "    # normalize\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "    # 2. create layer model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # 3. compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 4. train model \n",
    "    model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "\n",
    "    # 5. calculate loss and accuaracy of the result\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    print('\\n- TEST accuracy :', test_acc)\n",
    "\n",
    "\n",
    "    # 6. predict image\n",
    "    predictions = model.predict(test_images)\n",
    "\n",
    "    # print results\n",
    "    print(\"\\n- train image shape : \\n\",train_images.shape)\n",
    "    print(\"\\n- train labels length : \\n\", train_labels.shape[0])\n",
    "    print(\"\\n- train labels : \\n\", train_labels)\n",
    "    print(\"\\n- test image shape : \\n\", test_images.shape)\n",
    "    print(\"\\n- test labels length : \\n\", test_labels.shape[0])\n",
    "    print()\n",
    "    \n",
    "    # print images\n",
    "    i = 0\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_image(i, predictions, test_labels, test_images, class_names)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_value_array(i, predictions,  test_labels)\n",
    "    plt.savefig('pictures/ANN1.png')\n",
    "\n",
    "    i = 12\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_image(i, predictions, test_labels, test_images, class_names)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_value_array(i, predictions,  test_labels)\n",
    "    plt.savefig('pictures/ANN2.png')\n",
    "\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img, class_names):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% (true:{})\".format(class_names[predicted_label],\n",
    "                                    100*np.max(predictions_array),\n",
    "                                    class_names[true_label]),\n",
    "                                    color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "    num_classes = 10\n",
    "    \n",
    "    \n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    # image shape : 28*28 = data features\n",
    "    num_features = 784\n",
    "\n",
    "    # 1st layer num of neurons\n",
    "    hidden_layer_1 = 64\n",
    "    \n",
    "    # 2nd layer num of neurons\n",
    "    hidden_layer_2 = 128\n",
    "\n",
    "    # Training parameters\n",
    "    learning_rate = 0.05\n",
    "    training_steps = 3000\n",
    "    batch_size = 512\n",
    "    interval = 300\n",
    "\n",
    "\n",
    "    # Training data를 float32 자료형으로 형변환 해줍니다.\n",
    "    x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "    \n",
    "    # 2차원 이미지를 1차원으로 변형합니다.\n",
    "    x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "    \n",
    "    # 값을 [0, 255] 에서 [0, 1]으로 정규화 해줍니다.\n",
    "    x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "    # training data를 무작위로 선정하고, batch_size만큼 나눠주면서 초기화를 진행합니다.\n",
    "    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_data = train_data.repeat().shuffle(10000).batch(batch_size).prefetch(1)\n",
    "\n",
    "\n",
    "    # weight 값들을 무작위로 초기화합니다.\n",
    "    random_normal = tf.initializers.RandomNormal()\n",
    "\n",
    "    # 각 layer에 들어갈 Weight, bias들을 할당해 줍니다.\n",
    "    weights = {\n",
    "        'h1': tf.Variable(random_normal([num_features, hidden_layer_1])),\n",
    "        'h2': tf.Variable(random_normal([hidden_layer_1, hidden_layer_2])),\n",
    "        'out': tf.Variable(random_normal([hidden_layer_2, num_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([hidden_layer_1])),\n",
    "        'b2': tf.Variable(tf.zeros([hidden_layer_2])),\n",
    "        'out': tf.Variable(tf.zeros([num_classes]))\n",
    "    }\n",
    "\n",
    "\n",
    "    # Training을 실제로 구현하는 부분입니다.\n",
    "    for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "        # W 와 b 파라메터를 갱신하기 위해 함수를 호출합니다.\n",
    "        params_optimization(batch_x, batch_y, weights, biases, num_classes, learning_rate)\n",
    "\n",
    "        if step % interval == 0:\n",
    "            '''\n",
    "            neural_net() 함수는 model 생성에 사용되는 함수입니다.\n",
    "            neural_net() 함수를 채워 pred를 완성해보도록 하겠습니다.\n",
    "            '''\n",
    "            pred = neural_net(batch_x, weights, biases)\n",
    "            \n",
    "            loss = cross_entropy(pred, batch_y, num_classes)\n",
    "            acc = accuracy(pred, batch_y)\n",
    "            print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
    "\n",
    "\n",
    "    # Test를 진행하여 실제 정확도를 확인합니다.\n",
    "    pred = neural_net(x_test, weights, biases)\n",
    "    print(\"Test Accuracy: %f\" % accuracy(pred, y_test))\n",
    "    \n",
    "    \n",
    "    # 결과를 시각화합니다.\n",
    "    plot_neural_network_results(pred, x_test, y_test, class_names)\n",
    "\n",
    "\n",
    "    \n",
    "# 인공 신경망 함수입니다.\n",
    "'''\n",
    "def neural_net(x, weights, biases) 함수를 채워보세요.\n",
    "'''\n",
    "def neural_net(x, weights, biases):\n",
    "    \n",
    "    # 총 2개의 layer로 이뤄져 있으며, fully connected 연산 후 sigmoid 함수에 적용하여 값을 비선형으로 만들어줍니다.\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1']) \n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "    \n",
    "    return tf.nn.softmax(out_layer)\n",
    "\n",
    "\n",
    "# Cross-Entropy loss function에 대한 함수입니다.\n",
    "def cross_entropy(y_pred, y_true, num_classes):\n",
    "\n",
    "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
    "    \n",
    "    # 값 중에 min 값이 1e-8, max 값이 1.0 이 넘어가는 값이 없도록 바운더리를 지정합니다.\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-8, 1.)\n",
    "    \n",
    "    # cross-entropy를 수식으로 입력해 보세요.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
    "\n",
    "\n",
    "# 정확도(accuracy) 를 측정하는 함수입니다.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "\n",
    "# 파라메터들을 갱신하는 함수입니다. \n",
    "def params_optimization(x, y, weights, biases, num_classes, learning_rate):\n",
    "    # GradientTape() 함수를 묶어서 gradient를 자동 계산하도록 돕습니다.\n",
    "    with tf.GradientTape() as gt:\n",
    "        pred = neural_net(x, weights, biases)\n",
    "        loss = cross_entropy(pred, y, num_classes)\n",
    "        \n",
    "    # variable을 업데이트합니다.\n",
    "    variables_to_update = list(weights.values()) + list(biases.values())\n",
    "\n",
    "    # gradient를 계산합니다.\n",
    "    gradients = gt.gradient(loss, variables_to_update)\n",
    "    \n",
    "    # 파라메터(weight)들을 갱신하기 위한 함수를 지정해줍니다.\n",
    "    optimizer = tf.optimizers.Adagrad(learning_rate)\n",
    "    \n",
    "    # optimizer로 W와 b를 갱신합니다.\n",
    "    optimizer.apply_gradients(zip(gradients, variables_to_update))\n",
    "    \n",
    "\n",
    "def plot_neural_network_results(pred, x_test, y_test, class_names):\n",
    "    # 결과를 시각화 하는 함수입니다.\n",
    "    n_images = 10\n",
    "    test_images = x_test[:n_images]\n",
    "    predictions = pred\n",
    "\n",
    "    plt.figure(figsize=(7,10))\n",
    "    for i in range(n_images):\n",
    "        plt.subplot(5,2,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(np.reshape(test_images[i], [28, 28]), cmap=plt.cm.binary)\n",
    "        plt.xlabel(\"True : {} (Predict : {})\".format(class_names[y_test[i]],\n",
    "                                    class_names[np.argmax(predictions.numpy()[i])]))\n",
    "    plt.savefig('pictures/ANN3.png')\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Backpropagation\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    # Input 값을 다음과 같이 할당합니다.\n",
    "    w_0 = 2; x_0 = -1; w_1 = -3; x_1 = -2; w_2 = -3\n",
    "\n",
    "    # Forward propatation 은 차례로 모델의 값을 입력하는 방식입니다.\n",
    "    # f(w, x) 를 다음과 같이 각 재정의를 통해서 선언합니다.\n",
    "    h = -(w_0 * x_0 + w_1 * x_1 + w_2)\n",
    "    g = 1 + np.exp(h)\n",
    "    f = 1/g\n",
    "\n",
    "    # 거꾸로 Back propagation을 진행해봅시다:\n",
    "    # 첫번째 미분 대상은 f = 1 / g 입니다.\n",
    "    dfdg = -1/(g**2)\n",
    "\n",
    "    # 다음 미분 대상은 g = 1 + exp(h) 입니다.\n",
    "    dgdh = np.exp(h)\n",
    "    \n",
    "    # 세번째 미분 대상은 h = -(w_0 * x_0 + w_1 * x_1 + w_2) 입니다.\n",
    "    dhdw_0 = -x_0\n",
    "    dhdx_0 = -w_0\n",
    "    dhdw_1 = -x_1\n",
    "    dhdx_1 = -w_1\n",
    "    dhdw_2 = -1\n",
    "\n",
    "    # Chain rule 을 적용하여 값을 구해보세요.\n",
    "    dfdw_0 = dfdg * dgdh * dhdw_0\n",
    "    dfdx_0 = dfdg * dgdh * dhdx_0\n",
    "    dfdw_1 = dfdg * dgdh * dhdw_1\n",
    "    dfdx_1 = dfdg * dgdh * dhdx_1\n",
    "    dfdw_2 = dfdg * dgdh * dhdw_2\n",
    "    \n",
    "    return dfdw_0, dfdx_0, dfdw_1, dfdx_1, dfdw_2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
