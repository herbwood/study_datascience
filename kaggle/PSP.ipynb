{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Solving Process\n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Data\n",
    "#### 2. Checking Datas\n",
    "#### 3. Explanatory Data Analysis\n",
    "#### 4. Feature Engineering\n",
    "#### 5. Model Selection\n",
    "#### 6. Evaluation and Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Data Checking  \n",
    "***train, test 데이터 모두 확인해보기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "train.tail()\n",
    "train.shape\n",
    "train.info()\n",
    "train.describe()\n",
    "\n",
    "test.head()\n",
    "test.tail()\n",
    "test.shape\n",
    "test.info()\n",
    "test.describe()\n",
    "\n",
    "rows = train.shape[0]\n",
    "columns = train.shape[1]\n",
    "print('The train dataset contains {} rows and {} columns'.format(rows, columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checking Missing Data  \n",
    "- train, test 데이터 모두 확인해보기\n",
    "- msno로 시각화 해보기 -> (누락된 데이터가 너무 많으면 사용하지 않음!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    msg = 'column : {:>10}\\t Percent of Nan value : {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() / df_train[col].shape[0]))\n",
    "    print(msg)\n",
    "    \n",
    "for col in df_test.columns:\n",
    "    msg = 'column : {:>10}\\t Percent of Nan value : {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0]))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df=df_train.iloc[:, :], figsize=(8,8), color=(0.8, 0.5, 0.2))\n",
    "\n",
    "msno.matrix(df=df_train.iloc[:, :], figsize=(8,8), color=(0.8, 0.5, 0.2))\n",
    "\n",
    "msno.bar(df=df_test.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Checking Target Label  \n",
    "- 0,1로 분류 가능한 레이블이 어떤 분포를 가지고 있는지 시각적으로 확인해보기  \n",
    "- 극단적인 분포면 도움이 되지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (18,8))\n",
    "\n",
    "df_train['Survived'].value_counts().plot.pie(explode = [0, 0.1], \n",
    "                                             autopct='%1.1f%%',\n",
    "                                            ax=ax[0],\n",
    "                                            shadow=True)\n",
    "ax[0].set_title('Pie plot - Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived', data=df_train, ax=ax[1])\n",
    "ax[1].set_title('Count plot - Survived')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Checking Data Types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categorical, ordinal, continuous  \n",
    "- MetaData 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Checking number and ratio between all the features and target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = True).count()\n",
    "df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).sum()\n",
    "pd.crosstab(df_train['Pclass'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the relation between all the features and target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***bar, pie, distplot, countplot, violinplot, kdeplot 등을 활용***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot\n",
    "y_position = 1.02\n",
    "fig, ax = plt.subplots(1,2,figsize=(18,8))\n",
    "df_train['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'], ax=ax[0])\n",
    "ax[0].set_title('Number of Passengers By Pclass', y=y_position)\n",
    "ax[0].set_ylabel('Count')\n",
    "sns.countplot('Pclass', hue='Survived', data=df_train, ax=ax[1])\n",
    "ax[1].set_title('Pclass : Survived vs Dead', y=y_position)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdeplot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "sns.kdeplot(df_train.dropna()[df_train.dropna()['Survived'] == 1]['Age'], ax=ax)\n",
    "sns.kdeplot(df_train.dropna()[df_train.dropna()['Survived'] == 0]['Age'], ax=ax)\n",
    "plt.legend(['Survived == 1', 'Survived == 0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violinplot\n",
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "sns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=df_train, scale='count', split=True,ax=ax[0])\n",
    "ax[0].set_title('Pclass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10))\n",
    "sns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=df_train, scale='count', split=True,ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize relationship between 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorplot 1\n",
    "sns.factorplot('Pclass', 'Survived', hue = 'Sex', data=df_train, size=6, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorplot 2\n",
    "sns.factorplot(x='Sex', y='Survived', col='Pclass', data=df_train, saturation=.5,\n",
    "              size=9, aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 특성 합쳐서 분석해보기  \n",
    "#### (예 형제,자매 + 부모,자녀 = 가족)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
    "\n",
    "print('Maximum size of Family :', df_train['FamilySize'].max())\n",
    "print('Minimum size of Family :', df_train['FamilySize'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 비대칭 정보에 대해 log 취해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distplot\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "g = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\n",
    "g = g.legend(loc='best')\n",
    "\n",
    "df_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()\n",
    "\n",
    "df_train['Fare'] = df_train['Fare'].map(lambda i : np.log(i) if i > 0 else 0)\n",
    "df_test['Fare'] = df_test['Fare'].map(lambda i : np.log(i) if i >0 else 0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "g = sns.distplot(df_train['Fare'], color = 'b', label = 'Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\n",
    "g = g.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fill Null values  \n",
    "- 다른 특성을 이용하여 누락 데이터 채우기  \n",
    "( 예 이름에서 이니셜을 뽑아내고 이니셜의 평균 나이로 누락된 나이 데이터 채우기)  \n",
    "- 가장 많은 소속으로 채우기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***다른 특성을 이용하여 Null value 채우기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial 뽑아내기\n",
    "df_train['Initial'] = df_train.Name.str.extract('([A-Za-z]+)\\.')\n",
    "df_test['Initial'] = df_test.Name.str.extract('([A-Za-z]+)\\.')\n",
    "\n",
    "# crosstab으로 수 확인\n",
    "pd.crosstab(df_train['Initial'], df_train['Sex']).T.style.background_gradient(cmap='summer_r')\n",
    "\n",
    "# 각 initial별 평균 나이 확인\n",
    "df_train['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
    "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)\n",
    "\n",
    "df_test['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
    "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mr'],inplace=True)\n",
    "df_train.groupby('Initial').mean()\n",
    "\n",
    "# initial별 평균으로 null 값 채워주기\n",
    "df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mr'),'Age'] = 33\n",
    "df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Mrs'),'Age'] = 36\n",
    "df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Master'),'Age'] = 5\n",
    "df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Miss'),'Age'] = 22\n",
    "df_train.loc[(df_train.Age.isnull())&(df_train.Initial=='Other'),'Age'] = 46\n",
    "\n",
    "df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mr'),'Age'] = 33\n",
    "df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Mrs'),'Age'] = 36\n",
    "df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Master'),'Age'] = 5\n",
    "df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Miss'),'Age'] = 22\n",
    "df_test.loc[(df_test.Age.isnull())&(df_test.Initial=='Other'),'Age'] = 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***가장 많은 소속으로 null value 채우기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Embarked has ', sum(df_train['Embarked'].isnull()), 'Null values')\n",
    "df_train['Embarked'].fillna('S', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 구간 데이터를 범주 데이터로 바꿔보기  \n",
    "- 직접 다 바꾸거나  \n",
    "- 함수를 활용하거나(apply)  \n",
    "- pandas qcut으로 전달된 bins에 따라 구간 나눠줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method1\n",
    "df_train['Age_cat'] = 0\n",
    "df_train.loc[df_train['Age'] < 10, 'Age_cat'] = 0\n",
    "df_train.loc[(10 <= df_train['Age']) & (df_train['Age'] < 20), 'Age_cat'] = 1\n",
    "df_train.loc[(20 <= df_train['Age']) & (df_train['Age'] < 30), 'Age_cat'] = 2\n",
    "df_train.loc[(30 <= df_train['Age']) & (df_train['Age'] < 40), 'Age_cat'] = 3\n",
    "df_train.loc[(40 <= df_train['Age']) & (df_train['Age'] < 50), 'Age_cat'] = 4\n",
    "df_train.loc[(50 <= df_train['Age']) & (df_train['Age'] < 60), 'Age_cat'] = 5\n",
    "df_train.loc[(60 <= df_train['Age']) & (df_train['Age'] < 70), 'Age_cat'] = 6\n",
    "df_train.loc[70 <= df_train['Age'], 'Age_cat'] = 7\n",
    "\n",
    "df_test['Age_cat'] = 0\n",
    "df_test.loc[df_test['Age'] < 10, 'Age_cat'] = 0\n",
    "df_test.loc[(10 <= df_test['Age']) & (df_test['Age'] < 20), 'Age_cat'] = 1\n",
    "df_test.loc[(20 <= df_test['Age']) & (df_test['Age'] < 30), 'Age_cat'] = 2\n",
    "df_test.loc[(30 <= df_test['Age']) & (df_test['Age'] < 40), 'Age_cat'] = 3\n",
    "df_test.loc[(40 <= df_test['Age']) & (df_test['Age'] < 50), 'Age_cat'] = 4\n",
    "df_test.loc[(50 <= df_test['Age']) & (df_test['Age'] < 60), 'Age_cat'] = 5\n",
    "df_test.loc[(60 <= df_test['Age']) & (df_test['Age'] < 70), 'Age_cat'] = 6\n",
    "df_test.loc[70 <= df_test['Age'], 'Age_cat'] = 7\n",
    "\n",
    "# method 2\n",
    "def category_age(x):\n",
    "    if x < 10:\n",
    "        return 0\n",
    "    elif x < 20:\n",
    "        return 1\n",
    "    elif x < 30:\n",
    "        return 2\n",
    "    elif x < 40:\n",
    "        return 3\n",
    "    elif x < 50:\n",
    "        return 4\n",
    "    elif x < 60:\n",
    "        return 5\n",
    "    elif x < 70:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "    \n",
    "df_train['Age_cat_2'] = df_train['Age'].apply(category_age)\n",
    "\n",
    "df_train.drop(['Age', 'Age_cat_2'], axis=1, inplace=True)\n",
    "df_test.drop(['Age'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 문자열 데이터를 수치형 데이터로 바꾸기  \n",
    "- map 활용(Series용)  \n",
    "- apply는 DataFrame용!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Initial'] = df_train['Initial'].map({'Master' : 0, 'Miss' : 1, 'Mr' : 2, 'Mrs' : 3, 'Other' : 4})\n",
    "df_test['Initial'] = df_test['Initial'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4})\n",
    "\n",
    "df_train['Embarked'].unique()\n",
    "\n",
    "df_train['Embarked'].value_counts()\n",
    "\n",
    "df_train['Embarked'] = df_train['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "df_test['Embarked'] = df_test['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "df_train['Embarked'].isnull().any()\n",
    "\n",
    "df_train['Sex'] = df_train['Sex'].map({'female': 0, 'male': 1})\n",
    "df_test['Sex'] = df_test['Sex'].map({'female': 0, 'male': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Heatmap으로 시각화해보기  \n",
    "- 예측하고자 하는 레이블과 가장 강한 상관관계를 가지고 있는 특성 파악하기  \n",
    "- 서로 상관관계가 강한 특성들이 있는지 확인해보기  \n",
    "(상관관계가 1 혹은 -1이 나온다는 것은 얻을 수 있는 정보가 하나라는 뜻!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = df_train[['Survived', 'Pclass', 'Sex', 'Fare', 'Embarked', 'FamilySize', 'Initial', 'Age_cat']]\n",
    "\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(heatmap_data.astype(float).corr(), linewidth=0.1, vmax=1.0,\n",
    "           square = True, cmap=colormap, linecolor='white', annot=True, annot_kws={'size' : 16})\n",
    "\n",
    "del heatmap_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 One-Hot Encoding  \n",
    "- one-hot 인코딩으로 범주형 데이터 변형시켜주기(pd.get_dummies)   \n",
    "- sklearn Labelencoder + OnehotEncoder로도 가능!)  \n",
    "(카테고리 수가 많은 경우에는 어떻게?)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['Initial'], prefix='Initial')\n",
    "df_test = pd.get_dummies(df_test, columns=['Initial'], prefix='Initial')\n",
    "\n",
    "df_train.head()\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=['Embarked'], prefix='Embarked')\n",
    "df_test = pd.get_dummies(df_test, columns=['Embarked'], prefix='Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Drop Columns  \n",
    "- 불필요한 column들 drop해주기  \n",
    "- 예측하고자하느 레이블 제외하고 column이 같은지 확인해주기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "df_test.drop(['PassengerId', 'Name',  'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "df_train.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 train, validation, test set 분리해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
