{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Solving Process\n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Data\n",
    "#### 2. Checking Datas\n",
    "#### 3. Explanatory Data Analysis\n",
    "#### 4. Feature Engineering\n",
    "#### 5. Model Selection\n",
    "#### 6. Evaluation and Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Data Checking  \n",
    "***train, test 데이터 모두 확인해보기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "train.tail()\n",
    "train.shape\n",
    "train.info()\n",
    "train.describe()\n",
    "\n",
    "test.head()\n",
    "test.tail()\n",
    "test.shape\n",
    "test.info()\n",
    "test.describe()\n",
    "\n",
    "rows = train.shape[0]\n",
    "columns = train.shape[1]\n",
    "print('The train dataset contains {} rows and {} columns'.format(rows, columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checking Missing Data  \n",
    "***train, test 데이터 모두 확인해보기***  \n",
    "***msno로 시각화 해보기*** -> (누락된 데이터가 너무 많으면 사용하지 않음!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    msg = 'column : {:>10}\\t Percent of Nan value : {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() / df_train[col].shape[0]))\n",
    "    print(msg)\n",
    "    \n",
    "for col in df_test.columns:\n",
    "    msg = 'column : {:>10}\\t Percent of Nan value : {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0]))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df=df_train.iloc[:, :], figsize=(8,8), color=(0.8, 0.5, 0.2))\n",
    "\n",
    "msno.matrix(df=df_train.iloc[:, :], figsize=(8,8), color=(0.8, 0.5, 0.2))\n",
    "\n",
    "msno.bar(df=df_test.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Checking Target Label  \n",
    "***0,1로 분류 가능한 레이블이 어떤 분포를 가지고 있는지 시각적으로 확인해보기***   \n",
    "-> 극단적인 분포면 도움이 되지 않음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (18,8))\n",
    "\n",
    "df_train['Survived'].value_counts().plot.pie(explode = [0, 0.1], \n",
    "                                             autopct='%1.1f%%',\n",
    "                                            ax=ax[0],\n",
    "                                            shadow=True)\n",
    "ax[0].set_title('Pie plot - Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived', data=df_train, ax=ax[1])\n",
    "ax[1].set_title('Count plot - Survived')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Checking Data Types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***categorical, ordinal, continuous***   \n",
    "***MetaData 만들기***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Checking number and ratio between all the features and target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = True).count()\n",
    "df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).sum()\n",
    "pd.crosstab(df_train['Pclass'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the relation between all the features and target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***bar, pie, distplot, countplot, violinplot, kdeplot 등을 활용***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_position = 1.02\n",
    "fig, ax = plt.subplots(1,2,figsize=(18,8))\n",
    "df_train['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'], ax=ax[0])\n",
    "ax[0].set_title('Number of Passengers By Pclass', y=y_position)\n",
    "ax[0].set_ylabel('Count')\n",
    "sns.countplot('Pclass', hue='Survived', data=df_train, ax=ax[1])\n",
    "ax[1].set_title('Pclass : Survived vs Dead', y=y_position)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
